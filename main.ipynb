{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(os.getcwd(), 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(os.getcwd(), 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['rectal_temp', 'pulse', 'respiratory_rate','nasogastric_reflux_ph', \n",
    "                  'packed_cell_volume', 'total_protein', 'abdomo_protein', 'lesion_1']\n",
    "categorical_num_cols = []\n",
    "categorical_str_cols = ['surgery', 'age', 'temp_of_extremities', 'peripheral_pulse', 'mucous_membrane', 'capillary_refill_time', 'pain', \n",
    "                        'peristalsis', 'abdominal_distention', 'nasogastric_tube', 'nasogastric_reflux', 'rectal_exam_feces', 'abdomen', \n",
    "                        'abdomo_appearance', 'cp_data']\n",
    "target_col = ['outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1235, 24)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train[numerical_cols + categorical_num_cols + categorical_str_cols + target_col]\n",
    "test = test[numerical_cols + categorical_num_cols + categorical_str_cols]\n",
    "target = train.pop('outcome')\n",
    "target = target.astype('category')\n",
    "target = target.cat.codes\n",
    "train['target'] = target\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['died', 'euthanized', 'lived'], dtype='object')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling missing values\n",
    "for name in numerical_cols:\n",
    "    train[name].fillna(train[name].mean())\n",
    "for name in categorical_str_cols:\n",
    "    train[name].fillna(train[name].value_counts().iloc[0])\n",
    "# fix data types\n",
    "train[numerical_cols] = train[numerical_cols].astype('float32')\n",
    "train[categorical_str_cols] = train[categorical_str_cols].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling missing values\n",
    "for name in numerical_cols:\n",
    "    test[name].fillna(train[name].mean())\n",
    "for name in categorical_str_cols:\n",
    "    test[name].fillna(train[name].value_counts().iloc[0])\n",
    "# fix data types\n",
    "test[numerical_cols] = test[numerical_cols].astype('float32')\n",
    "test[categorical_str_cols] = test[categorical_str_cols].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensorflow dataset\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=128):\n",
    "    df = dataframe.copy()\n",
    "    labels = df.pop('target')\n",
    "    df = {name: np.array(value)[:, tf.newaxis] for name, value in df.items()}\n",
    "    ds = tf.data.Dataset.from_tensor_slices((df, labels))\n",
    "\n",
    "    if shuffle==True:\n",
    "        ds = ds.shuffle(buffer_size=1000)\n",
    "    \n",
    "    ds = ds.batch(batch_size=batch_size)\n",
    "    ds = ds.prefetch(buffer_size=1000)\n",
    "\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert train to tensor dataset\n",
    "train_ds = df_to_dataset(train, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int8, numpy=array([1, 2, 1, 0, 0], dtype=int8)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing train dataset\n",
    "[(train_features, label_batch)] = train_ds.take(1)\n",
    "label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization features transformation function\n",
    "def get_normalization_layer(name, dataset):\n",
    "    normalizer = tf.keras.layers.Normalization(axis=None)\n",
    "    feature_ds = dataset.map(lambda x,y: x[name])\n",
    "    normalizer.adapt(feature_ds)\n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       "array([-1.2712613, -0.256483 ,  1.3925325, -0.7638746,  1.3925325],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test normalization feature transformation function\n",
    "normalizer_layer = get_normalization_layer('rectal_temp', train_ds)\n",
    "normalizer_layer(train_features['rectal_temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical featuers transformation function\n",
    "def get_category_encoding_layer(name, dataset, dtype='string', max_tokens=None):\n",
    "    if dtype == 'string':\n",
    "        index = tf.keras.layers.StringLookup(max_tokens=max_tokens)\n",
    "    else:\n",
    "        index = tf.keras.layers.IntegerLookup(max_tokens=max_tokens)\n",
    "\n",
    "    feature_ds = dataset.map(lambda x,y: x[name])\n",
    "    index.adapt(feature_ds)\n",
    "    encoding = tf.keras.layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "\n",
    "    return lambda feature: encoding(index(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=float32, numpy=array([0., 1., 1., 1., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test categorical encoding function\n",
    "encoding_layer = get_category_encoding_layer('pain', train_ds, 'string')\n",
    "encoding_layer(train_features['pain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input and output for model\n",
    "batch_size = 128\n",
    "train_ds = df_to_dataset(train, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "all_inputs = []\n",
    "encoded_features = []\n",
    "for name in numerical_cols:\n",
    "    num_col = tf.keras.Input(shape=(1,), name=name, dtype='float32')\n",
    "    normalization_layer = get_normalization_layer(name, train_ds)\n",
    "    encoded_numeric_col = normalization_layer(num_col)\n",
    "    all_inputs.append(num_col)\n",
    "    encoded_features.append(encoded_numeric_col)\n",
    "\n",
    "for name in categorical_str_cols:\n",
    "    categorical_col = tf.keras.Input(shape=(1,), name=name, dtype='string')\n",
    "    encoding_str_layer = get_category_encoding_layer(name, train_ds, 'string')\n",
    "    encoded_str_col = encoding_str_layer(categorical_col)\n",
    "    all_inputs.append(categorical_col)\n",
    "    encoded_features.append(encoded_str_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model\n",
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(units=64, activation='relu')(all_features)\n",
    "x = tf.keras.layers.Dense(units=32, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "output = tf.keras.layers.Dense(units=3)(x)\n",
    "\n",
    "model = tf.keras.Model(all_inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 4ms/step - loss: 1.0772 - accuracy: 0.3806\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9516 - accuracy: 0.5449\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8908 - accuracy: 0.6089\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8393 - accuracy: 0.6300\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7935 - accuracy: 0.6567\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7632 - accuracy: 0.6883\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7499 - accuracy: 0.6753\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7236 - accuracy: 0.6891\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7077 - accuracy: 0.6996\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.7093\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6735 - accuracy: 0.7069\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6722 - accuracy: 0.7150\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6536 - accuracy: 0.7279\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.7296\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6389 - accuracy: 0.7320\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6305 - accuracy: 0.7425\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6279 - accuracy: 0.7457\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6078 - accuracy: 0.7619\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5952 - accuracy: 0.7522\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5908 - accuracy: 0.7547\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5959 - accuracy: 0.7595\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5730 - accuracy: 0.7757\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5723 - accuracy: 0.7652\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.7660\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5547 - accuracy: 0.7660\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5472 - accuracy: 0.7781\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5447 - accuracy: 0.7854\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5348 - accuracy: 0.7903\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5219 - accuracy: 0.7879\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.8040\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.8138\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.8057\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.8049\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.8138\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4910 - accuracy: 0.8008\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.8089\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.8356\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.8275\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.8267\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.8202\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.8227\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.8413\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.8340\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8389\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.8445\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8421\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8429\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8445\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3798 - accuracy: 0.8599\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3766 - accuracy: 0.8534\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3777 - accuracy: 0.8591\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3666 - accuracy: 0.8680\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3648 - accuracy: 0.8680\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3584 - accuracy: 0.8753\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8858\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3438 - accuracy: 0.8737\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3385 - accuracy: 0.8866\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3281 - accuracy: 0.8834\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.8818\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3257 - accuracy: 0.8842\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3218 - accuracy: 0.8891\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2969 - accuracy: 0.8964\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3013 - accuracy: 0.8955\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3052 - accuracy: 0.8980\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2850 - accuracy: 0.9085\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2857 - accuracy: 0.8955\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2754 - accuracy: 0.9117\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2622 - accuracy: 0.9150\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2649 - accuracy: 0.9101\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2612 - accuracy: 0.9239\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2524 - accuracy: 0.9134\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2546 - accuracy: 0.9126\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2606 - accuracy: 0.9109\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2488 - accuracy: 0.9166\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.9174\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2317 - accuracy: 0.9255\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2315 - accuracy: 0.9271\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2284 - accuracy: 0.9296\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2324 - accuracy: 0.9150\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2125 - accuracy: 0.9385\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2196 - accuracy: 0.9304\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2111 - accuracy: 0.9287\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2130 - accuracy: 0.9263\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2018 - accuracy: 0.9296\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2016 - accuracy: 0.9296\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9401\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1861 - accuracy: 0.9401\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1840 - accuracy: 0.9433\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1789 - accuracy: 0.9466\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1781 - accuracy: 0.9506\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1761 - accuracy: 0.9498\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1680 - accuracy: 0.9498\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1707 - accuracy: 0.9474\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1725 - accuracy: 0.9401\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1542 - accuracy: 0.9547\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1631 - accuracy: 0.9514\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1596 - accuracy: 0.9441\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1520 - accuracy: 0.9579\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1485 - accuracy: 0.9538\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1415 - accuracy: 0.9587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22857673110>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run model\n",
    "model.fit(train_ds, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {name : np.array(value)[:, tf.newaxis] for name, value in test.items()}\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'surgery', 'age', 'hospital_number', 'rectal_temp', 'pulse',\n",
       "       'respiratory_rate', 'temp_of_extremities', 'peripheral_pulse',\n",
       "       'mucous_membrane', 'capillary_refill_time', 'pain', 'peristalsis',\n",
       "       'abdominal_distention', 'nasogastric_tube', 'nasogastric_reflux',\n",
       "       'nasogastric_reflux_ph', 'rectal_exam_feces', 'abdomen',\n",
       "       'packed_cell_volume', 'total_protein', 'abdomo_appearance',\n",
       "       'abdomo_protein', 'surgical_lesion', 'lesion_1', 'lesion_2', 'lesion_3',\n",
       "       'cp_data'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/824 [..............................] - ETA: 28s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "824/824 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_argmax = [np.argmax(x) for x in prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.593696</td>\n",
       "      <td>-4.121152</td>\n",
       "      <td>5.824048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.991136</td>\n",
       "      <td>-3.015255</td>\n",
       "      <td>0.003747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.564877</td>\n",
       "      <td>-5.081720</td>\n",
       "      <td>2.993718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.924227</td>\n",
       "      <td>5.715120</td>\n",
       "      <td>-1.311954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.737739</td>\n",
       "      <td>-5.472135</td>\n",
       "      <td>5.715425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>2.533762</td>\n",
       "      <td>-0.677752</td>\n",
       "      <td>-1.388781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>-0.634482</td>\n",
       "      <td>1.858314</td>\n",
       "      <td>-1.062467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>2.311933</td>\n",
       "      <td>-3.466755</td>\n",
       "      <td>1.228221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>0.387666</td>\n",
       "      <td>-4.923575</td>\n",
       "      <td>2.656766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>-0.264433</td>\n",
       "      <td>-3.867047</td>\n",
       "      <td>4.210302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>824 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0   -3.593696 -4.121152  5.824048\n",
       "1    3.991136 -3.015255  0.003747\n",
       "2    1.564877 -5.081720  2.993718\n",
       "3   -3.924227  5.715120 -1.311954\n",
       "4   -0.737739 -5.472135  5.715425\n",
       "..        ...       ...       ...\n",
       "819  2.533762 -0.677752 -1.388781\n",
       "820 -0.634482  1.858314 -1.062467\n",
       "821  2.311933 -3.466755  1.228221\n",
       "822  0.387666 -4.923575  2.656766\n",
       "823 -0.264433 -3.867047  4.210302\n",
       "\n",
       "[824 rows x 3 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df = prediction_df.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.5936959e+00, -4.1211519e+00,  5.8240476e+00],\n",
       "       [ 3.9911361e+00, -3.0152555e+00,  3.7468821e-03],\n",
       "       [ 1.5648769e+00, -5.0817199e+00,  2.9937179e+00],\n",
       "       ...,\n",
       "       [ 2.3119330e+00, -3.4667549e+00,  1.2282214e+00],\n",
       "       [ 3.8766631e-01, -4.9235754e+00,  2.6567659e+00],\n",
       "       [-2.6443252e-01, -3.8670473e+00,  4.2103019e+00]], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'died'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['died', 'euthanized', 'lived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_prediction = [categories[x] for x in prediction_argmax]\n",
    "submission_id = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': submission_id, 'outcome': submission_prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
